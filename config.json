{
  "corpusPath": "./corpus",
  "collectionName": "rag_collection",
  "embedModel": "nomic-embed-text",
  "mainModel": "gemma2:2b-instruct-q2_K",
  "contextSize": 4096,
  "currentTemperature": 0.1,
  "numberOfResults": 6,
  "chatMaxMessages": 16,
  "assistantMaxMessageSize": 512,
  "modelDescriptions": [
    {
      "name": "llama3.1",
      "description": "General use. Context length of 128k tokens."
    },
    {
      "name": "gemma2:2b-instruct-q2_K",
      "description": "Small model to use with CPU only devices. Context length of 8,192 tokens."
    },
    {
      "name": "qwen2",
      "description": "Good for coding and math. Context length of 128k tokens."
    },
    {
      "name": "nomic-embed-text",
      "description": "High-performing open embedding model. Context length of 8,192 tokens."
    },
    {
      "name": "llava",
      "description": "Vision model, generates text description of an image. Image resolution up to 1344px in length or height."
    }
  ]
}
